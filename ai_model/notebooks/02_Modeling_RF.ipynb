{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 1] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn ê´€ë ¨\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (Colab í™˜ê²½)\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •\n",
    "BASE_DIR = '/content/U-Sto_AI'\n",
    "DATA_PATH = f\"{BASE_DIR}/dataset/data_ml/phase4_training_data.csv\"\n",
    "MODEL_DIR = f\"{BASE_DIR}/saved_models/random_forest\"\n",
    "RESULT_DIR = f\"{BASE_DIR}/results/plots\"\n",
    "\n",
    "for d in [MODEL_DIR, RESULT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ë° ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 2] ë°ì´í„° ë¡œë“œ ë° ë¶„í• \n",
    "# Phase 4ì—ì„œ ì´ë¯¸ ì •í•´ë‘” 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„' ì»¬ëŸ¼ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# ì…ë ¥ ë³€ìˆ˜(X) ì •ì˜ (ëª¨ë¸ì— ë“¤ì–´ê°ˆ Feature)\n",
    "# Phase 4ì—ì„œ '_Code'ë¡œ ë³€í™˜í•œ ê°’ë“¤ê³¼ ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "features = [\n",
    "    'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ë¶€ì„œê°€í˜¹ë„', 'ê°€ê²©ë¯¼ê°ë„', 'ì¥ë¹„ì¤‘ìš”ë„', \n",
    "    'ë¦¬ë“œíƒ€ì„ë“±ê¸‰', 'ì·¨ë“ì›”',\n",
    "    'G2Bëª©ë¡ëª…_Code', 'ë¬¼í’ˆë¶„ë¥˜ëª…_Code', 'ìš´ìš©ë¶€ì„œì½”ë“œ_Code', 'ìº í¼ìŠ¤_Code'\n",
    "]\n",
    "target = 'ì‹¤ì œìˆ˜ëª…' # ì˜ˆì¸¡ ëª©í‘œ: ì´ ìˆ˜ëª…\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„ë¦¬ (Phase 4ì˜ ë¡œì§ ì¤€ìˆ˜)\n",
    "train_mask = df['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] == 'Train'\n",
    "valid_mask = df['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] == 'Valid'\n",
    "test_mask  = df['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] == 'Test'\n",
    "pred_mask  = df['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] == 'Prediction' # (== í•™ìŠµë°ì´í„°ì—¬ë¶€ 'N')\n",
    "\n",
    "X_train = df.loc[train_mask, features]\n",
    "y_train = df.loc[train_mask, target]\n",
    "\n",
    "X_val = df.loc[valid_mask, features]\n",
    "y_val = df.loc[valid_mask, target]\n",
    "\n",
    "X_test = df.loc[test_mask, features]\n",
    "y_test = df.loc[test_mask, target]\n",
    "\n",
    "# ì˜ˆì¸¡ ëŒ€ìƒ (í˜„ì¬ ìš´ìš© ì¤‘ì¸ ìì‚°)\n",
    "X_pred_target = df.loc[pred_mask, features]\n",
    "df_pred_final = df.loc[pred_mask].copy()\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ\")\n",
    "print(f\"   - Train (í•™ìŠµ): {X_train.shape}\")\n",
    "print(f\"   - Valid (ê²€ì¦): {X_val.shape}\")\n",
    "print(f\"   - Pred  (ì‹¤ì „): {X_pred_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 3] Phase 5-1. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë§\n",
    "print(\"\\nğŸš€ [Phase 5-1] ë² ì´ìŠ¤ë¼ì¸(ê¸°ë³¸) ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# 1. ëª¨ë¸ ì´ˆê¸°í™” (ê¸°ë³¸ê°’)\n",
    "rf_base = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. í•™ìŠµ (Train ë°ì´í„°ë§Œ ì‚¬ìš©)\n",
    "rf_base.fit(X_train, y_train)\n",
    "\n",
    "# 3. ê²€ì¦ (Valid ë°ì´í„° ì‚¬ìš©)\n",
    "y_val_pred = rf_base.predict(X_val)\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"ğŸ“Š [Baseline Result]\")\n",
    "print(f\"   - RMSE (ì˜¤ì°¨): {rmse:.4f} ë…„\")\n",
    "print(f\"   - MAE  (ì˜¤ì°¨): {mae:.4f} ë…„\")\n",
    "print(f\"   - RÂ² (ì„¤ëª…ë ¥): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 4] Phase 5-2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "print(\"\\nğŸ”§ [Phase 5-2] GridSearchCV ìµœì í™” ì‹œì‘ (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\")\n",
    "\n",
    "# 1. íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # ë‚˜ë¬´ì˜ ê°œìˆ˜\n",
    "    'max_depth': [10, 20, None],      # ë‚˜ë¬´ì˜ ê¹Šì´ (ê³¼ì í•© ì œì–´)\n",
    "    'min_samples_split': [2, 5],      # ë¶„í•  ì¡°ê±´\n",
    "    'min_samples_leaf': [1, 2, 4]     # ì ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ\n",
    "}\n",
    "\n",
    "# 2. K-Fold ì„¤ì • (5ë“±ë¶„)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Grid Search ì„¤ì •\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=kf,\n",
    "    scoring='neg_root_mean_squared_error', # RMSEë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì í™”\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ ìˆ˜í–‰\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. ìµœì  ê²°ê³¼ ë„ì¶œ\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"ğŸ‰ ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}\")\n",
    "\n",
    "# 6. Test ì…‹(ìµœì¢… ë³´ë¥˜ ë°ì´í„°)ìœ¼ë¡œ ìµœì¢… ê²€ì¦\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "final_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"ğŸ† [Final Test Result] RMSE: {final_rmse:.4f}, RÂ²: {final_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 5] Phase 5-3. Feature Importance ë¶„ì„ ë° ì‹œê°í™”\n",
    "print(\"\\nğŸ” [Phase 5-3] ì¤‘ìš” ë³€ìˆ˜ ë¶„ì„...\")\n",
    "\n",
    "# ì¤‘ìš”ë„ ì¶”ì¶œ\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances (Random Forest)\", fontsize=15)\n",
    "sns.barplot(x=importances[indices], y=[features[i] for i in indices], palette=\"viridis\")\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# ê·¸ë˜í”„ ì €ì¥\n",
    "plot_path = f\"{RESULT_DIR}/rf_feature_importance.png\"\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ’¾ ì¤‘ìš”ë„ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {plot_path}\")\n",
    "\n",
    "# (ì˜µì…˜) ëª¨ë¸ ê²½ëŸ‰í™” ì œì•ˆ\n",
    "low_impact_features = [features[i] for i in indices if importances[i] < 0.01]\n",
    "if low_impact_features:\n",
    "    print(f\"ğŸ’¡ [Tip] ì˜í–¥ë ¥ì´ ë‚®ì€ ë³€ìˆ˜ë“¤: {low_impact_features}\")\n",
    "    print(\"   -> ì¶”í›„ ëª¨ë¸ ê²½ëŸ‰í™” ì‹œ ì´ ë³€ìˆ˜ë“¤ì„ ì œì™¸í•˜ê³  ì¬í•™ìŠµì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 6] Phase 6. ìµœì¢… ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥\n",
    "print(\"\\nğŸ”® [Phase 6] ìš´ìš© ìì‚° ìˆ˜ëª… ì˜ˆì¸¡ ìˆ˜í–‰...\")\n",
    "\n",
    "# 1. Prediction ë°ì´í„°ì…‹ì— ëŒ€í•´ 'ì´ ìˆ˜ëª…' ì˜ˆì¸¡\n",
    "pred_total_life = best_rf.predict(X_pred_target)\n",
    "\n",
    "# 2. ê²°ê³¼ ë§¤í•‘ ë° ì”ì—¬ìˆ˜ëª… ê³„ì‚°\n",
    "# ê³µì‹: ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª… = AIê°€_ì˜ˆì¸¡í•œ_ì´ìˆ˜ëª… - í˜„ì¬_ìš´ìš©ì—°ì°¨\n",
    "df_pred_final['ì˜ˆì¸¡ìˆ˜ëª…'] = pred_total_life\n",
    "df_pred_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'] = df_pred_final['ì˜ˆì¸¡ìˆ˜ëª…'] - df_pred_final['ìš´ìš©ì—°ì°¨']\n",
    "\n",
    "# 3. ë§ˆì´ë„ˆìŠ¤ ê°’ ë³´ì • (ì´ë¯¸ ìˆ˜ëª…ì´ ë‹¤í•œ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "# or ë¶„ì„ì„ ìœ„í•´ ë§ˆì´ë„ˆìŠ¤ ê°’ì„ ê·¸ëŒ€ë¡œ ë‘ê³  'êµì²´ 1ìˆœìœ„'ë¡œ í™œìš©í•  ìˆ˜ë„ ìˆìŒ\n",
    "# ì—¬ê¸°ì„œëŠ” 0ìœ¼ë¡œ ë³´ì •í•˜ë˜, ì›ë³¸ ì˜ˆì¸¡ê°’ë„ ë‚¨ê¹ë‹ˆë‹¤.\n",
    "df_pred_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…_Raw'] = df_pred_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…']\n",
    "df_pred_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'] = df_pred_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'].clip(lower=0)\n",
    "\n",
    "# 4. ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "joblib.dump(best_rf, f\"{MODEL_DIR}/best_model.pkl\")\n",
    "with open(f\"{MODEL_DIR}/params.json\", 'w') as f:\n",
    "    json.dump(grid_search.best_params_, f)\n",
    "\n",
    "# 5. ì„±ëŠ¥ ë¦¬í¬íŠ¸ CSV ì €ì¥\n",
    "perf_df = pd.DataFrame({\n",
    "    'Model': ['RandomForest'],\n",
    "    'RMSE': [final_rmse],\n",
    "    'R2': [final_r2],\n",
    "    'Best_Params': [str(grid_search.best_params_)]\n",
    "})\n",
    "perf_df.to_csv(f\"{BASE_DIR}/results/performance_comparison.csv\", index=False)\n",
    "\n",
    "# 6. ìµœì¢… ê²°ê³¼ íŒŒì¼ ì €ì¥ (Phase 6 ì‚°ì¶œë¬¼)\n",
    "final_output_path = f\"{BASE_DIR}/dataset/data_ml/phase6_prediction_result.csv\"\n",
    "# ì£¼ìš” ì»¬ëŸ¼ ìœ„ì£¼ë¡œ ì •ë ¬í•˜ì—¬ ì €ì¥\n",
    "output_cols = [\n",
    "    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'G2Bëª©ë¡ëª…', 'ìš´ìš©ë¶€ì„œëª…', 'ì·¨ë“ì¼ì', 'ë‚´ìš©ì—°ìˆ˜', 'ìš´ìš©ì—°ì°¨',\n",
    "    'ì˜ˆì¸¡ìˆ˜ëª…', 'ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…', 'ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…_Raw', \n",
    "    'ë¶€ì„œê°€í˜¹ë„', 'ì¥ë¹„ì¤‘ìš”ë„' # ë¶„ì„ìš© ì°¸ê³ \n",
    "]\n",
    "df_pred_final[output_cols].to_csv(final_output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_DIR}/best_model.pkl\")\n",
    "print(f\"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {final_output_path}\")\n",
    "print(f\"ğŸ‘‰ ì˜ˆì¸¡ ëŒ€ìƒ {len(df_pred_final)}ê±´ì— ëŒ€í•œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
