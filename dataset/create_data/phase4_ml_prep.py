import pandas as pd
import numpy as np
import os
from pandas.errors import EmptyDataError

# ---------------------------------------------------------
# 0. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
# ê¸°ì¤€ì¼ì„ ì‹œìŠ¤í…œ 'ì˜¤ëŠ˜'ë¡œ ì¡ìœ¼ë©´ ì½”ë“œë¥¼ ëŒë¦´ ë•Œë§ˆë‹¤ ìˆ˜ëª…ê³¼ ì”ì—¬ì¼ìˆ˜ê°€ ë‹¬ë¼ì ¸ì„œ 
# ëª¨ë¸ ì¬í˜„ì„±(Reproducibility)ì´ ë–¨ì–´ì§€ë¯€ë¡œ íŠ¹ì • ì¼ìë¡œ ê³ ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
FIXED_TODAY_STR = "2026-02-10"
today = pd.to_datetime(FIXED_TODAY_STR).normalize()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle")
SAVE_DIR = os.path.join(BASE_DIR, "data_ml")
os.makedirs(SAVE_DIR, exist_ok=True)

print("ğŸ“‚ [Phase 4] AI í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

# ë¹ˆ ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë³‘í•© ì‹œ KeyErrorê°€ ë‚˜ì§€ ì•Šë„ë¡ í•„ìˆ˜ ì»¬ëŸ¼ì„ ëª…ì‹œ
COLS_DU = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']
COLS_DP = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ì', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ']

def load_csv_safe(filename, required=False, expected_cols=None):
    """ì•ˆì „í•˜ê²Œ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ DataFrameì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    filepath = os.path.join(LOAD_DIR, filename)
    if os.path.exists(filepath):
        try:
            return pd.read_csv(filepath)
        except EmptyDataError:
            return pd.DataFrame(columns=expected_cols) if expected_cols else pd.DataFrame()
    else:
        if required:
            print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ëˆ„ë½: {filename}")
            exit()
        return pd.DataFrame(columns=expected_cols) if expected_cols else pd.DataFrame()

# 1. ì›ì²œ ë°ì´í„° ë¡œë“œ
df_op = load_csv_safe('04_01_operation_master.csv', required=True)    
df_du = load_csv_safe('05_01_disuse_list.csv', expected_cols=COLS_DU)      
df_dp = load_csv_safe('06_01_disposal_list.csv', expected_cols=COLS_DP)    

print(f"   - ì›ì²œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ìš´ìš© ëŒ€ì¥ {len(df_op)}ê±´")

# í•˜ë‚˜ì˜ ë¬¼í’ˆì´ ì—¬ëŸ¬ ë²ˆ ë¶ˆìš© ì´ë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
# ìµœì‹  ì´ë ¥(í™•ì •ì¼ì ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ) í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì¤‘ë³µì„ ì œê±°í•´ì•¼ 1:1 ë³‘í•©ì´ ê¹”ë”í•˜ê²Œ ë¨
def drop_duplicates_safe(df, date_col, conf_date_col):
    if not df.empty:
# ì›ë³¸ DataFrameì´ í•¨ìˆ˜ í˜¸ì¶œë¡œ ì¸í•´ ì˜ˆìƒì¹˜ ëª»í•˜ê²Œ ë³€ê²½ë˜ì§€ ì•Šë„ë¡ ë³µì‚¬ë³¸ì—ì„œ ì‘ì—…
        df = df.copy()
        # ê¸°ì¤€ì¼ì ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        if conf_date_col in df.columns:
            # í™•ì •ì¼ì ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ë©´ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œë„ ì •ë ¬
            df[conf_date_col] = pd.to_datetime(df[conf_date_col], errors='coerce')
            df = df.sort_values(
                by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', conf_date_col, date_col],
                ascending=[True, False, False],
                kind='mergesort'
            )
        else:
            # í™•ì •ì¼ìê°€ ì—†ë”ë¼ë„ ìµœì†Œí•œ ë¬¼í’ˆê³ ìœ ë²ˆí˜¸+ê¸°ì¤€ì¼ì ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ì´ë ¥ì„ ì„ íƒ
            df = df.sort_values(
                by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', date_col],
                ascending=[True, False],
                kind='mergesort'
            )
        return df.drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'], keep='first')
    return df

df_du = drop_duplicates_safe(df_du, 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì')
df_dp = drop_duplicates_safe(df_dp, 'ì²˜ë¶„í™•ì •ì¼ì', 'ì²˜ë¶„í™•ì •ì¼ì') # ì²˜ë¶„ì€ ì¼ìê°€ í•˜ë‚˜ë¿ì´ë¯€ë¡œ ë™ì¼í•˜ê²Œ ì²˜ë¦¬

# ---------------------------------------------------------
# 1. ë°ì´í„° ë³‘í•© (Master Table ìƒì„±)
# ---------------------------------------------------------
print("   1. ìƒì• ì£¼ê¸° ë³‘í•© (ìš´ìš©+ë¶ˆìš©+ì²˜ë¶„)...")

# [Review ë°˜ì˜] ë³‘í•© ì „ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜
def get_existing_cols(df, target_cols):
    return [c for c in target_cols if c in df.columns]

# ìš´ìš© ë§ˆìŠ¤í„°ì— ë¶ˆìš©, ì²˜ë¶„ ì´ë ¥ì„ Left Joinìœ¼ë¡œ ë¶™ì„
# (1) ë¶ˆìš© ì´ë ¥ ë³‘í•©
cols_du_exist = get_existing_cols(df_du, ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ'])
df_merged = pd.merge(df_op, df_du[cols_du_exist].rename(columns={'ì‚¬ìœ ': 'ë¶ˆìš©ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ': 'ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ'}), on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# (2) ì²˜ë¶„ ì´ë ¥ ë³‘í•©
cols_dp_exist = get_existing_cols(df_dp, ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ì', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ'])
df_merged = pd.merge(df_merged, df_dp[cols_dp_exist].rename(columns={'ìŠ¹ì¸ìƒíƒœ': 'ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ'}), on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
# ---------------------------------------------------------
# 2. ì „ì²˜ë¦¬ ë° ê²°ì¸¡ì¹˜ ë³´ì • 
# ---------------------------------------------------------
print("   2. ê²°ì¸¡ì¹˜ ë³´ì • ë° ê¸°ì¤€ì¼ ì‚°ì¶œ...")

date_cols = ['ì·¨ë“ì¼ì', 'ë¶ˆìš©ì¼ì', 'ë¶ˆìš©í™•ì •ì¼ì', 'ì²˜ë¶„í™•ì •ì¼ì']
for col in date_cols:
    if col in df_merged.columns:
        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')

# ìˆ˜ëª… ê³„ì‚°ì˜ ëì ì´ ë˜ëŠ” 'ì¢…ë£Œì¼'ì„ êµ¬í•˜ëŠ” ë¡œì§
# 1ìˆœìœ„: ì²˜ë¶„í™•ì •ì¼ì > 2ìˆœìœ„: ë¶ˆìš©í™•ì •ì¼ì
confirmed_end_date = (
    df_merged.get('ì²˜ë¶„í™•ì •ì¼ì', pd.Series(index=df_merged.index, dtype='datetime64[ns]'))
    .combine_first(df_merged.get('ë¶ˆìš©í™•ì •ì¼ì', pd.Series(index=df_merged.index, dtype='datetime64[ns]')))
)

# í™•ì •ì¼ìê°€ ì—†ì„ ê²½ìš° ë¶ˆìš©ì¼ìë¥¼ ì°¨ì„ ì±…ìœ¼ë¡œ ì‚¬ìš©
valid_disuse_date = df_merged['ë¶ˆìš©ì¼ì'].where(df_merged.get('ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ') == 'í™•ì •')

df_merged['ìµœì¢…ì¢…ë£Œì¼'] = confirmed_end_date.combine_first(valid_disuse_date)
# ì¢…ë£Œì¼ì´ ì—†ìœ¼ë©´ 'í˜„ì¬ ìš´ìš© ì¤‘'ì´ë¼ëŠ” ëœ»ì´ë¯€ë¡œ ê¸°ì¤€ì¼ì„ todayë¡œ ì„¤ì •
df_merged['ê¸°ì¤€ì¼'] = df_merged['ìµœì¢…ì¢…ë£Œì¼'].fillna(today)

# ì•ˆì „í•œ ì»¬ëŸ¼ ë§¤í•‘ ë¡œì§
df_final = pd.DataFrame(index=df_merged.index)
df_final['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'] = df_merged['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸']
df_final['ì·¨ë“ê¸ˆì•¡'] = df_merged.get('ì·¨ë“ê¸ˆì•¡', 0)
df_final['ìš´ìš©ë¶€ì„œì½”ë“œ'] = df_merged.get('ìš´ìš©ë¶€ì„œì½”ë“œ')
df_final['ìº í¼ìŠ¤'] = df_merged.get('ìº í¼ìŠ¤')
df_final['ì·¨ë“ì¼ì'] = df_merged.get('ì·¨ë“ì¼ì')
df_final['ë¶ˆìš©ì¼ì'] = df_merged.get('ë¶ˆìš©ì¼ì')
df_final['ë¶ˆìš©ì‚¬ìœ '] = df_merged.get('ë¶ˆìš©ì‚¬ìœ ')
df_final['ë¬¼í’ˆìƒíƒœ'] = df_merged.get('ë¬¼í’ˆìƒíƒœ')
df_final['ì²˜ë¶„ë°©ì‹'] = df_merged.get('ì²˜ë¶„ë°©ì‹')
df_final['ê¸°ì¤€ì¼'] = df_merged['ê¸°ì¤€ì¼']

# Fallbackì„ í¬í•¨í•œ ëª…ì¹­ ë§¤í•‘
df_final['G2Bëª©ë¡ëª…'] = df_merged['G2B_ëª©ë¡ëª…'] if 'G2B_ëª©ë¡ëª…' in df_merged.columns else df_merged.get('G2Bëª©ë¡ëª…', pd.NA)
df_final['ë¬¼í’ˆë¶„ë¥˜ëª…'] = df_merged['ë¬¼í’ˆë¶„ë¥˜ëª…'] if 'ë¬¼í’ˆë¶„ë¥˜ëª…' in df_merged.columns else df_final['G2Bëª©ë¡ëª…']
df_final['ìš´ìš©ë¶€ì„œëª…'] = df_merged['ìš´ìš©ë¶€ì„œ'] if 'ìš´ìš©ë¶€ì„œ' in df_merged.columns else df_merged.get('ìš´ìš©ë¶€ì„œëª…', pd.NA)
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_merged['ë‚´ìš©ì—°ìˆ˜'] if 'ë‚´ìš©ì—°ìˆ˜' in df_merged.columns else pd.Series(5, index=df_merged.index)

# ê²°ì¸¡ì¹˜ ë³´ì • (ê°€ê²©ì´ 0ì´ê±°ë‚˜ ì—†ëŠ” ê²½ìš° ì¤‘ì•™ê°’ìœ¼ë¡œ, ë‚´ìš©ì—°ìˆ˜ê°€ ì—†ìœ¼ë©´ ìµœë¹ˆê°’(ë³´í†µ 5ë…„)ìœ¼ë¡œ)
valid_prices = df_final.loc[df_final['ì·¨ë“ê¸ˆì•¡'] > 0, 'ì·¨ë“ê¸ˆì•¡']
median_price = valid_prices.median() if not valid_prices.empty else 1000000 # ê¸°ë³¸ê°’ìœ¼ë¡œ 100ë§Œì› ì‚¬ìš©
df_final['ì·¨ë“ê¸ˆì•¡'] = df_final['ì·¨ë“ê¸ˆì•¡'].fillna(median_price).replace(0, median_price)

df_final['ë‚´ìš©ì—°ìˆ˜'] = df_final['ë‚´ìš©ì—°ìˆ˜'].fillna(df_final['ë‚´ìš©ì—°ìˆ˜'].mode()[0] if not df_final['ë‚´ìš©ì—°ìˆ˜'].mode().empty else 5)
df_final = df_final.dropna(subset=['ì·¨ë“ì¼ì']) # ì‹œì‘ì¼ì´ ì—†ìœ¼ë©´ ìˆ˜ëª… ê³„ì‚°ì´ ë¶ˆê°€í•˜ë¯€ë¡œ ì œê±°

# ---------------------------------------------------------
# 3. íŒŒìƒ ë³€ìˆ˜ ìƒì„± ë° íƒ€ê²Ÿ ì •ì˜
# ---------------------------------------------------------
print("   3. íŒŒìƒë³€ìˆ˜ ìƒì„± ë° ì´ìƒì¹˜ ì²˜ë¦¬...")

# ìš´ìš©ì—°ì°¨ ì‚°ì¶œ (ë…„ ë‹¨ìœ„ í™˜ì‚°)
df_final['ìš´ìš©ì—°ì°¨'] = ((df_final['ê¸°ì¤€ì¼'] - df_final['ì·¨ë“ì¼ì']).dt.days.clip(lower=0) / 365.0).round(2)

# í•™ìŠµì— ì‚¬ìš©í•  "ìˆ˜ëª…ì´ë‹¤ í•œ(Dead)" ë°ì´í„°ë¥¼ ì •ì˜í•˜ëŠ” ë¡œì§ (ì •ë‹µì§€ í™•ë³´)
is_disposal = df_final['ì²˜ë¶„ë°©ì‹'].isin(['íê¸°', 'ë©¸ì‹¤'])
is_sale_eol = (df_final['ì²˜ë¶„ë°©ì‹'] == 'ë§¤ê°') & df_final['ë¶ˆìš©ì‚¬ìœ '].isin(['ê³ ì¥/íŒŒì†', 'ë…¸í›„í™”(ì„±ëŠ¥ì €í•˜)', 'ìˆ˜ë¦¬ë¹„ìš©ê³¼ë‹¤', 'êµ¬í˜•í™”', 'ë‚´êµ¬ì—°í•œ ê²½ê³¼(ë…¸í›„í™”)'])

df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] = np.where(is_disposal | is_sale_eol, 'Y', 'N')

# --- IQR ê¸°ë°˜ ì´ìƒì¹˜(Outlier) ì œê±° ---
# ì´ìœ : í•™ìŠµ ë°ì´í„°ì— ìˆ˜ëª…ì´ 0.1ë…„ì´ê±°ë‚˜ 50ë…„ì¸ ê·¹ë‹¨ì  ë°ì´í„°ê°€ ì„ì—¬ ìˆìœ¼ë©´ ëª¨ë¸ì´ í”ë“¤ë¦¼.
train_cond = df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'
if train_cond.sum() > 0 and df_final.loc[train_cond, 'ìš´ìš©ì—°ì°¨'].notna().any():
    Q1 = df_final.loc[train_cond, 'ìš´ìš©ì—°ì°¨'].quantile(0.25)
    Q3 = df_final.loc[train_cond, 'ìš´ìš©ì—°ì°¨'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 2.0* IQR
    upper_bound = Q3 + 2.0 * IQR

    # ì´ìƒì¹˜ ì œì™¸ ë° ê²°ê³¼ ì¶œë ¥
    outlier_mask = (df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y') & ((df_final['ìš´ìš©ì—°ì°¨'] < lower_bound) | (df_final['ìš´ìš©ì—°ì°¨'] > upper_bound))
    df_outliers = df_final[outlier_mask]
    
    if not df_outliers.empty:
        print(f"      * [ì´ìƒì¹˜ ì œê±°] ì •ìƒë²”ìœ„({lower_bound:.2f}~{upper_bound:.2f}ë…„) ì™¸ {len(df_outliers)}ê±´ ì œì™¸")

    valid_data_mask = (df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'N') | ((df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y') & (~outlier_mask))
    df_final = df_final[valid_data_mask].copy()

    # ì´ìƒì¹˜ ë°ì´í„° í†µê³„ ì¶œë ¥ (ë„¤ê°€ ì›í–ˆë˜ ë¶€ë¶„!)
    if not df_outliers.empty:
        outlier_min = df_outliers['ìš´ìš©ì—°ì°¨'].min()
        outlier_max = df_outliers['ìš´ìš©ì—°ì°¨'].max()
        outlier_mode = df_outliers['ìš´ìš©ì—°ì°¨'].mode()[0] if not df_outliers['ìš´ìš©ì—°ì°¨'].mode().empty else 'ì—†ìŒ'
        
        print(f"      * [ì´ìƒì¹˜ ìƒì„¸ ë¶„ì„] ì œì™¸ ì˜ˆì •ì¸ ë°ì´í„° {len(df_outliers)}ê±´ì˜ ìˆ˜ëª… ì •ë³´:")
        print(f"        - ì •ìƒ í—ˆìš© ë²”ìœ„: {lower_bound:.2f}ë…„ ~ {upper_bound:.2f}ë…„")
        print(f"        - í†µê³„ â” ìµœì†Œê°’: {outlier_min}ë…„ / ìµœëŒ€ê°’: {outlier_max}ë…„ / ìµœë¹ˆê°’: {outlier_mode}ë…„")
        
        # ì–´ë–¤ ë¬¼í’ˆë“¤ì´ ì£¼ë¡œ ê±¸ë ¸ëŠ”ì§€ ìƒìœ„ 5ê°œ í’ˆëª©ëª… í™•ì¸
        top_items = df_outliers['G2Bëª©ë¡ëª…'].value_counts().head(3).to_dict()
        print(f"        - ì£¼ë¡œ ê±¸ëŸ¬ì§„ í’ˆëª© Top 3: {top_items}")

# ì¶”ê°€ íŒŒìƒ ë³€ìˆ˜ ì‚°ì¶œ
df_final['ì”ì—¬ë‚´ìš©ì—°ìˆ˜'] = (df_final['ë‚´ìš©ì—°ìˆ˜'] - df_final['ìš´ìš©ì—°ì°¨']).round(2)

def get_severity(dept_name):
    if pd.isna(dept_name): return 1.0
    dept_str = str(dept_name)
    if any(k in dept_str for k in ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê³µí•™', 'ì „ì‚°', 'AI', 'ì •ë³´','ê³µê³¼', 'ì»´í“¨í„°']): return 1.3
    if any(k in dept_str for k in ['ì—°êµ¬', 'ì‹¤í—˜', 'ê³¼í•™']): return 1.2
    return 1.0

df_final['ë¶€ì„œê°€í˜¹ë„'] = df_final['ìš´ìš©ë¶€ì„œëª…'].apply(get_severity)
df_final['ëˆ„ì ì‚¬ìš©ë¶€í•˜'] = (df_final['ìš´ìš©ì—°ì°¨'] * df_final['ë¶€ì„œê°€í˜¹ë„']).round(2)
df_final['ê³ ì¥ì„ë°•ë„'] = ((df_final['ìš´ìš©ì—°ì°¨'] / df_final['ë‚´ìš©ì—°ìˆ˜'].replace(0, np.nan)) ** 2).clip(0, 1).round(2)

# ì˜ˆì‚°/êµ¬ë§¤ ê´€ë ¨ ì§€í‘œ
df_final['ê°€ê²©ë¯¼ê°ë„'] = (np.log1p(df_final['ì·¨ë“ê¸ˆì•¡']) / np.log1p(100000000)).clip(0, 1).round(2)
df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] = df_final['ì·¨ë“ê¸ˆì•¡'].apply(lambda x: 0 if x < 5000000 else (1 if x < 30000000 else 2))
df_final['ì¥ë¹„ì¤‘ìš”ë„'] = ((df_final['ê°€ê²©ë¯¼ê°ë„'] * 0.7) + ((df_final['ë¦¬ë“œíƒ€ì„ë“±ê¸‰'] * 0.5) * 0.3)).round(2)
df_final['ì·¨ë“ì›”'] = df_final['ì·¨ë“ì¼ì'].dt.month

# ---------------------------------------------------------
# 4. ì»¬ëŸ¼ì •ì˜ì„œ ê¸°ë°˜ ê²°ê³¼ Placeholder ì„¸íŒ… ë° ì¸ì½”ë”©
# ---------------------------------------------------------
# íƒ€ê²Ÿ ì„¸íŒ… (ì‹¤ì œìˆ˜ëª…: í•™ìŠµì— ì“°ì¼ Yê°’)
df_final['ì‹¤ì œìˆ˜ëª…'] = np.nan
df_final.loc[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 'ì‹¤ì œìˆ˜ëª…'] = df_final.loc[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 'ìš´ìš©ì—°ì°¨']

# ì»¬ëŸ¼ì •ì˜ì„œ í•„ìˆ˜ ì‚°ì¶œë¬¼ ë¹ˆì¹¸(Placeholder) ì²˜ë¦¬
# (ì´ ê°’ë“¤ì€ Phase 6 ì˜ˆì¸¡ ë‹¨ê³„ë‚˜ LLM í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì±„ì›Œì§)
df_final['ì„œë¹„ìŠ¤ê³„ìˆ˜'] = np.nan 
df_final['ì‹¤ì œì”ì—¬ìˆ˜ëª…'] = np.where(df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 0.0, np.nan)
df_final['ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…'] = np.nan
df_final['(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰'] = 0
df_final['ì•ˆì „ì¬ê³ '] = 0
df_final['(ì›”ë³„)í•„ìš”ìˆ˜ëŸ‰'] = 0
df_final['AIì˜ˆì¸¡ê³ ì¥ì¼'] = pd.NaT
df_final['ì•ˆì „ë²„í¼'] = 0.0
df_final['ê¶Œì¥ë°œì£¼ì¼'] = pd.NaT
df_final['ì˜ˆì¸¡ì‹¤í–‰ì¼ì'] = today.strftime('%Y-%m-%d')

# ë²”ì£¼í˜• ìˆ˜ì¹˜í™” (ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë¼ë²¨ ì¸ì½”ë”©)
for col in ['G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ìº í¼ìŠ¤']:
    df_final[col] = df_final[col].fillna('Unknown').astype(str)
    df_final[f'{col}_Code'] = pd.factorize(df_final[col], sort=True)[0]

# ---------------------------------------------------------
# 5. ë°ì´í„° ë¶„í•  ë° ì €ì¥ (Train / Valid / Test / Pred)
# ---------------------------------------------------------
df_train_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'].copy().sort_values(by='ì·¨ë“ì¼ì')

# ì‹œê³„ì—´ì„±ì´ ìˆëŠ” ìì‚° ë°ì´í„°ì´ë¯€ë¡œ ëœë¤ ì…”í”Œë§ë³´ë‹¤ëŠ” ì·¨ë“ì¼ì ìˆœìœ¼ë¡œ ì˜ë¼ì„œ 
# ê³¼ê±° ë°ì´í„°ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” Time-Series Split ë°©ì‹ì„ í‰ë‚´ë‚´ëŠ” ê²ƒì´ ì¢‹ìŒ
n_total = len(df_train_source)
n_train, n_valid = int(n_total * 0.7), int(n_total * 0.2)

df_final['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Prediction' # ê¸°ë³¸ê°’ì€ ì˜ˆì¸¡ ëŒ€ìƒ
df_final.loc[df_train_source.iloc[:n_train].index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Train'
df_final.loc[df_train_source.iloc[n_train : n_train + n_valid].index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Valid'
df_final.loc[df_train_source.iloc[n_train + n_valid:].index,  'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Test'

# ìµœì¢… ì¶œë ¥ ì»¬ëŸ¼ ì§€ì • (ì»¬ëŸ¼ì •ì˜ì„œ ë§¤í•‘ ë°˜ì˜ & ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
output_cols = [
    # ì •ì  & ê¸°ë³¸ ì •ë³´
    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ìš´ìš©ë¶€ì„œëª…', 'ìº í¼ìŠ¤',
    'ì·¨ë“ì¼ì', 'ë¶ˆìš©ì¼ì', 'ì²˜ë¶„ë°©ì‹', 'ë¬¼í’ˆìƒíƒœ', 'ë¶ˆìš©ì‚¬ìœ ', 
    
    # íŒŒìƒ ë³€ìˆ˜ (Features)
    'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ìš´ìš©ì—°ì°¨', 'ì”ì—¬ë‚´ìš©ì—°ìˆ˜', 'ë¶€ì„œê°€í˜¹ë„', 'ëˆ„ì ì‚¬ìš©ë¶€í•˜',
    'ê³ ì¥ì„ë°•ë„', 'ê°€ê²©ë¯¼ê°ë„', 'ì¥ë¹„ì¤‘ìš”ë„', 'ë¦¬ë“œíƒ€ì„ë“±ê¸‰', 'ì·¨ë“ì›”',
    'G2Bëª©ë¡ëª…_Code', 'ë¬¼í’ˆë¶„ë¥˜ëª…_Code', 'ìš´ìš©ë¶€ì„œì½”ë“œ_Code', 'ìº í¼ìŠ¤_Code',
    
    # íƒ€ê²Ÿ ë° êµ¬ë¶„
    'ì‹¤ì œìˆ˜ëª…', 'í•™ìŠµë°ì´í„°ì—¬ë¶€', 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„',
    
    # ì˜ˆì¸¡ê°’/ê²°ê³¼ê°’ (ì»¬ëŸ¼ì •ì˜ì„œ ë§¤í•‘ ì™„ë²½ ëŒ€ì‘)
    'ì„œë¹„ìŠ¤ê³„ìˆ˜', 'ì‹¤ì œì”ì—¬ìˆ˜ëª…', 'ì˜ˆì¸¡ì”ì—¬ìˆ˜ëª…', '(ì›”ë³„)ê³ ì¥ì˜ˆìƒìˆ˜ëŸ‰', 'ì•ˆì „ì¬ê³ ', 
    '(ì›”ë³„)í•„ìš”ìˆ˜ëŸ‰', 'AIì˜ˆì¸¡ê³ ì¥ì¼', 'ì•ˆì „ë²„í¼', 'ê¶Œì¥ë°œì£¼ì¼', 'ì˜ˆì¸¡ì‹¤í–‰ì¼ì'
]

# [Review ë°˜ì˜] reindex ì „ ì»¬ëŸ¼ ëˆ„ë½ í™•ì¸
missing_cols = [c for c in output_cols if c not in df_final.columns]
if missing_cols:
    print(f"âš ï¸ ê²½ê³ : ë‹¤ìŒ ì»¬ëŸ¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_cols}")

df_export = df_final.reindex(columns=output_cols)
save_path = os.path.join(SAVE_DIR, 'phase4_training_data.csv')
df_export.to_csv(save_path, index=False, encoding='utf-8-sig')

print("-" * 50)
print(f"âœ… ì²˜ë¶„ ì™„ë£Œ(í•™ìŠµìš©) ë°ì´í„°: {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='Y'])} ê±´ (Train/Valid/Test ë¶„í•  ì™„ë£Œ)")
print(f"âœ… ìš´ìš© ì¤‘(ì˜ˆì¸¡ìš©) ë°ì´í„° : {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='N'])} ê±´")
print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")
print("-" * 50)