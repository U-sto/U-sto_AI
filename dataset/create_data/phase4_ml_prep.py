import pandas as pd
import numpy as np
import os
from pandas.errors import EmptyDataError

# ---------------------------------------------------------
# 0. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
# ê¸°ì¤€ì¼ì„ ì‹œìŠ¤í…œ 'ì˜¤ëŠ˜'ë¡œ ìž¡ìœ¼ë©´ ì½”ë“œë¥¼ ëŒë¦´ ë•Œë§ˆë‹¤ ìˆ˜ëª…ê³¼ ìž”ì—¬ì¼ìˆ˜ê°€ ë‹¬ë¼ì ¸ì„œ 
# ëª¨ë¸ ìž¬í˜„ì„±(Reproducibility)ì´ ë–¨ì–´ì§€ë¯€ë¡œ íŠ¹ì • ì¼ìžë¡œ ê³ ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
FIXED_TODAY_STR = "2026-02-10"
today = pd.to_datetime(FIXED_TODAY_STR).normalize()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOAD_DIR = os.path.join(BASE_DIR, "data_lifecycle")
SAVE_DIR = os.path.join(BASE_DIR, "data_ml")
os.makedirs(SAVE_DIR, exist_ok=True)

print("ðŸ“‚ [Phase 4] AI í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìž‘...")

# ë¹ˆ ë°ì´í„°í”„ë ˆìž„ì´ ë¡œë“œë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´, ë³‘í•© ì‹œ KeyErrorê°€ ë‚˜ì§€ ì•Šë„ë¡ í•„ìˆ˜ ì»¬ëŸ¼ì„ ëª…ì‹œ
COLS_RT = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë°˜ë‚©ì¼ìž', 'ë°˜ë‚©í™•ì •ì¼ìž', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']
COLS_DU = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ìž', 'ë¶ˆìš©í™•ì •ì¼ìž', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']
COLS_DP = ['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ìž', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ']

def load_csv_safe(filename, required=False, expected_cols=None):
    """ì•ˆì „í•˜ê²Œ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ê±°ë‚˜ ë¹„ì–´ìžˆìœ¼ë©´ ë¹ˆ DataFrameì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    filepath = os.path.join(LOAD_DIR, filename)
    if os.path.exists(filepath):
        try:
            return pd.read_csv(filepath)
        except EmptyDataError:
            return pd.DataFrame(columns=expected_cols) if expected_cols else pd.DataFrame()
    else:
        if required:
            print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ëˆ„ë½: {filename}")
            exit()
        return pd.DataFrame(columns=expected_cols) if expected_cols else pd.DataFrame()

# 1. ì›ì²œ ë°ì´í„° ë¡œë“œ
df_op = load_csv_safe('04_01_operation_master.csv', required=True) 
df_rt = load_csv_safe('04_03_return_list.csv', expected_cols=COLS_RT)      
df_du = load_csv_safe('05_01_disuse_list.csv', expected_cols=COLS_DU)      
df_dp = load_csv_safe('06_01_disposal_list.csv', expected_cols=COLS_DP)    

print(f"   - ì›ì²œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ìš´ìš© ëŒ€ìž¥ {len(df_op)}ê±´")

# í•˜ë‚˜ì˜ ë¬¼í’ˆì´ ì—¬ëŸ¬ ë²ˆ ë°˜ë‚©/ë¶ˆìš© ì´ë ¥ì„ ê°€ì§ˆ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ
# ìµœì‹  ì´ë ¥(í™•ì •ì¼ìž ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ) í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì¤‘ë³µì„ ì œê±°í•´ì•¼ 1:1 ë³‘í•©ì´ ê¹”ë”í•˜ê²Œ ë¨
def drop_duplicates_safe(df, date_col, conf_date_col):
    if not df.empty:
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        if conf_date_col in df.columns:
            df[conf_date_col] = pd.to_datetime(df[conf_date_col], errors='coerce')
            df = df.sort_values(by=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', conf_date_col, date_col], ascending=[True, False, False])
        return df.drop_duplicates(subset=['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸'], keep='first')
    return df

df_rt = drop_duplicates_safe(df_rt, 'ë°˜ë‚©ì¼ìž', 'ë°˜ë‚©í™•ì •ì¼ìž')
df_du = drop_duplicates_safe(df_du, 'ë¶ˆìš©ì¼ìž', 'ë¶ˆìš©í™•ì •ì¼ìž')
df_dp = drop_duplicates_safe(df_dp, 'ì²˜ë¶„í™•ì •ì¼ìž', 'ì²˜ë¶„í™•ì •ì¼ìž') # ì²˜ë¶„ì€ ì¼ìžê°€ í•˜ë‚˜ë¿ì´ë¯€ë¡œ ë™ì¼í•˜ê²Œ ì²˜ë¦¬

# ---------------------------------------------------------
# 1. ë°ì´í„° ë³‘í•© (Master Table ìƒì„±)
# ---------------------------------------------------------
print("   1. ìƒì• ì£¼ê¸° ë³‘í•© (ìš´ìš©+ë°˜ë‚©+ë¶ˆìš©+ì²˜ë¶„)...")

# ìš´ìš© ë§ˆìŠ¤í„°ì— ë°˜ë‚©, ë¶ˆìš©, ì²˜ë¶„ ì´ë ¥ì„ Left Joinìœ¼ë¡œ ë¶™ìž„
df_merged = pd.merge(df_op, df_rt[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë°˜ë‚©ì¼ìž', 'ë°˜ë‚©í™•ì •ì¼ìž', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']].rename(columns={'ìŠ¹ì¸ìƒíƒœ': 'ë°˜ë‚©ìŠ¹ì¸ìƒíƒœ', 'ì‚¬ìœ ': 'ë°˜ë‚©ì‚¬ìœ '}), on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged = pd.merge(df_merged, df_du[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ë¶ˆìš©ì¼ìž', 'ë¶ˆìš©í™•ì •ì¼ìž', 'ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ']].rename(columns={'ì‚¬ìœ ': 'ë¶ˆìš©ì‚¬ìœ ', 'ìŠ¹ì¸ìƒíƒœ': 'ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ'}), on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')
df_merged = pd.merge(df_merged, df_dp[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì²˜ë¶„ë°©ì‹', 'ì²˜ë¶„í™•ì •ì¼ìž', 'ë¬¼í’ˆìƒíƒœ', 'ìŠ¹ì¸ìƒíƒœ']].rename(columns={'ìŠ¹ì¸ìƒíƒœ': 'ì²˜ë¶„ìŠ¹ì¸ìƒíƒœ'}), on='ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', how='left')

# ---------------------------------------------------------
# 2. ì „ì²˜ë¦¬ ë° ê²°ì¸¡ì¹˜ ë³´ì • 
# ---------------------------------------------------------
print("   2. ê²°ì¸¡ì¹˜ ë³´ì • ë° ê¸°ì¤€ì¼ ì‚°ì¶œ...")

date_cols = ['ì·¨ë“ì¼ìž', 'ë°˜ë‚©ì¼ìž', 'ë¶ˆìš©ì¼ìž', 'ë°˜ë‚©í™•ì •ì¼ìž', 'ë¶ˆìš©í™•ì •ì¼ìž', 'ì²˜ë¶„í™•ì •ì¼ìž']
for col in date_cols:
    if col in df_merged.columns:
        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')

# ìˆ˜ëª… ê³„ì‚°ì˜ ëì ì´ ë˜ëŠ” 'ì¢…ë£Œì¼'ì„ êµ¬í•˜ëŠ” ë¡œì§
# 1ìˆœìœ„: ì²˜ë¶„ > 2ìˆœìœ„: ë¶ˆìš© > 3ìˆœìœ„: ë°˜ë‚© ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„ë¥¼ ë‘ .
confirmed_end_date = df_merged.get('ì²˜ë¶„í™•ì •ì¼ìž').combine_first(df_merged.get('ë¶ˆìš©í™•ì •ì¼ìž')).combine_first(df_merged.get('ë°˜ë‚©í™•ì •ì¼ìž'))
valid_ret_date = df_merged['ë°˜ë‚©ì¼ìž'].where(df_merged['ë°˜ë‚©ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •')
valid_disuse_date = df_merged['ë¶ˆìš©ì¼ìž'].where(df_merged['ë¶ˆìš©ìŠ¹ì¸ìƒíƒœ'] == 'í™•ì •')
fallback_end_date = valid_ret_date.combine_first(valid_disuse_date)

df_merged['ìµœì¢…ì¢…ë£Œì¼'] = confirmed_end_date.combine_first(fallback_end_date)
# ì¢…ë£Œì¼ì´ ì—†ìœ¼ë©´ 'í˜„ìž¬ ìš´ìš© ì¤‘'ì´ë¼ëŠ” ëœ»ì´ë¯€ë¡œ ê¸°ì¤€ì¼ì„ todayë¡œ ì„¤ì •
df_merged['ê¸°ì¤€ì¼'] = df_merged['ìµœì¢…ì¢…ë£Œì¼'].fillna(today)

# ë¨¸ì‹ ëŸ¬ë‹ìš© ìµœì¢… ë°ì´í„°í”„ë ˆìž„ ë¼ˆëŒ€ êµ¬ì¶•
df_final = df_merged[['ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'ì·¨ë“ê¸ˆì•¡', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ìº í¼ìŠ¤', 'ì·¨ë“ì¼ìž', 'ë°˜ë‚©ì¼ìž', 'ë¶ˆìš©ì¼ìž', 'ë°˜ë‚©ì‚¬ìœ ', 'ë¶ˆìš©ì‚¬ìœ ', 'ë¬¼í’ˆìƒíƒœ', 'ì²˜ë¶„ë°©ì‹', 'ê¸°ì¤€ì¼']].copy()
df_final['G2Bëª©ë¡ëª…'] = df_merged.get('G2B_ëª©ë¡ëª…', df_merged.get('G2Bëª©ë¡ëª…'))
df_final['ë¬¼í’ˆë¶„ë¥˜ëª…'] = df_merged.get('ë¬¼í’ˆë¶„ë¥˜ëª…', df_final['G2Bëª©ë¡ëª…'])
df_final['ìš´ìš©ë¶€ì„œëª…'] = df_merged.get('ìš´ìš©ë¶€ì„œ', df_merged.get('ìš´ìš©ë¶€ì„œëª…'))
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_merged.get('ë‚´ìš©ì—°ìˆ˜')

# ê²°ì¸¡ì¹˜ ë³´ì • (ê°€ê²©ì´ 0ì´ê±°ë‚˜ ì—†ëŠ” ê²½ìš° ì¤‘ì•™ê°’ìœ¼ë¡œ, ë‚´ìš©ì—°ìˆ˜ê°€ ì—†ìœ¼ë©´ ìµœë¹ˆê°’(ë³´í†µ 5ë…„)ìœ¼ë¡œ)
median_price = df_final.loc[df_final['ì·¨ë“ê¸ˆì•¡'] > 0, 'ì·¨ë“ê¸ˆì•¡'].median()
df_final['ì·¨ë“ê¸ˆì•¡'] = df_final['ì·¨ë“ê¸ˆì•¡'].fillna(median_price).replace(0, median_price)
df_final['ë‚´ìš©ì—°ìˆ˜'] = df_final['ë‚´ìš©ì—°ìˆ˜'].fillna(df_final['ë‚´ìš©ì—°ìˆ˜'].mode()[0] if not df_final['ë‚´ìš©ì—°ìˆ˜'].mode().empty else 5)
df_final = df_final.dropna(subset=['ì·¨ë“ì¼ìž']) # ì‹œìž‘ì¼ì´ ì—†ìœ¼ë©´ ìˆ˜ëª… ê³„ì‚°ì´ ë¶ˆê°€í•˜ë¯€ë¡œ ì œê±°

# ---------------------------------------------------------
# 3. íŒŒìƒ ë³€ìˆ˜ ìƒì„± ë° íƒ€ê²Ÿ ì •ì˜
# ---------------------------------------------------------
print("   3. íŒŒìƒë³€ìˆ˜ ìƒì„± ë° ì´ìƒì¹˜ ì²˜ë¦¬...")

# ìš´ìš©ì—°ì°¨ ì‚°ì¶œ (ë…„ ë‹¨ìœ„ í™˜ì‚°)
df_final['ìš´ìš©ì—°ì°¨'] = ((df_final['ê¸°ì¤€ì¼'] - df_final['ì·¨ë“ì¼ìž']).dt.days.clip(lower=0) / 365.0).round(2)

# í•™ìŠµì— ì‚¬ìš©í•  "ìˆ˜ëª…ì´ë‹¤ í•œ(Dead)" ë°ì´í„°ë¥¼ ì •ì˜í•˜ëŠ” ë¡œì§ (ì •ë‹µì§€ í™•ë³´)
is_disposal = df_final['ì²˜ë¶„ë°©ì‹'].isin(['íê¸°', 'ë©¸ì‹¤'])
is_sale_eol = (df_final['ì²˜ë¶„ë°©ì‹'] == 'ë§¤ê°') & df_final['ë¶ˆìš©ì‚¬ìœ '].isin(['ê³ ìž¥/íŒŒì†', 'ë…¸í›„í™”(ì„±ëŠ¥ì €í•˜)', 'ìˆ˜ë¦¬ë¹„ìš©ê³¼ë‹¤', 'êµ¬í˜•í™”', 'ë‚´êµ¬ì—°í•œ ê²½ê³¼(ë…¸í›„í™”)'])
is_return_repair = df_final['ë°˜ë‚©ì¼ìž'].notna() & (df_final['ë¬¼í’ˆìƒíƒœ'] == 'ì •ë¹„í•„ìš”í’ˆ')

df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] = np.where(is_disposal | is_sale_eol | is_return_repair, 'Y', 'N')

# --- IQR ê¸°ë°˜ ì´ìƒì¹˜(Outlier) ì œê±° ---
# ì´ìœ : í•™ìŠµ ë°ì´í„°ì— ìˆ˜ëª…ì´ 0.1ë…„ì´ê±°ë‚˜ 50ë…„ì¸ ê·¹ë‹¨ì  ë°ì´í„°ê°€ ì„žì—¬ ìžˆìœ¼ë©´ ëª¨ë¸ì´ í”ë“¤ë¦¼.
train_cond = df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'
Q1 = df_final.loc[train_cond, 'ìš´ìš©ì—°ì°¨'].quantile(0.25)
Q3 = df_final.loc[train_cond, 'ìš´ìš©ì—°ì°¨'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# ì˜ˆì¸¡í•´ì•¼ í•  ë°ì´í„°('N')ëŠ” ì‚´ë¦¬ê³ , í•™ìŠµ ë°ì´í„°('Y') ì¤‘ì—ì„œ ì •ìƒ ë²”ì£¼ì— ìžˆëŠ” ê²ƒë§Œ ë‚¨ê¹€
valid_data_mask = (df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'N') | ((df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y') & (df_final['ìš´ìš©ì—°ì°¨'] >= lower_bound) & (df_final['ìš´ìš©ì—°ì°¨'] <= upper_bound))
removed_count = len(df_final) - valid_data_mask.sum()
df_final = df_final[valid_data_mask].copy()
print(f"      * [ì´ìƒì¹˜ ì œê±°] ê·¹ë‹¨ì  ìˆ˜ëª…ì„ ê°€ì§„ í•™ìŠµ ë°ì´í„° {removed_count}ê±´ ì œì™¸ (ì •ìƒë²”ìœ„: {lower_bound:.2f} ~ {upper_bound:.2f}ë…„)")

# ì¶”ê°€ íŒŒìƒ ë³€ìˆ˜ ì‚°ì¶œ
df_final['ìž”ì—¬ë‚´ìš©ì—°ìˆ˜'] = (df_final['ë‚´ìš©ì—°ìˆ˜'] - df_final['ìš´ìš©ì—°ì°¨']).round(2)

def get_severity(dept_name):
    if pd.isna(dept_name): return 1.0
    dept_str = str(dept_name)
    if any(k in dept_str for k in ['ì†Œí”„íŠ¸ì›¨ì–´', 'ê³µí•™', 'ì „ì‚°', 'AI', 'ì •ë³´','ê³µê³¼', 'ì»´í“¨í„°']): return 1.3
    if any(k in dept_str for k in ['ì—°êµ¬', 'ì‹¤í—˜', 'ê³¼í•™']): return 1.2
    return 1.0

df_final['ë¶€ì„œê°€í˜¹ë„'] = df_final['ìš´ìš©ë¶€ì„œëª…'].apply(get_severity)
df_final['ëˆ„ì ì‚¬ìš©ë¶€í•˜'] = (df_final['ìš´ìš©ì—°ì°¨'] * df_final['ë¶€ì„œê°€í˜¹ë„']).round(2)
df_final['ê³ ìž¥ìž„ë°•ë„'] = ((df_final['ìš´ìš©ì—°ì°¨'] / df_final['ë‚´ìš©ì—°ìˆ˜']) ** 2).clip(0, 1).round(2)

# ì˜ˆì‚°/êµ¬ë§¤ ê´€ë ¨ ì§€í‘œ
df_final['ê°€ê²©ë¯¼ê°ë„'] = (np.log1p(df_final['ì·¨ë“ê¸ˆì•¡']) / np.log1p(100000000)).clip(0, 1).round(2)
df_final['ë¦¬ë“œíƒ€ìž„ë“±ê¸‰'] = df_final['ì·¨ë“ê¸ˆì•¡'].apply(lambda x: 0 if x < 5000000 else (1 if x < 30000000 else 2))
df_final['ìž¥ë¹„ì¤‘ìš”ë„'] = ((df_final['ê°€ê²©ë¯¼ê°ë„'] * 0.7) + ((df_final['ë¦¬ë“œíƒ€ìž„ë“±ê¸‰'] * 0.5) * 0.3)).round(2)
df_final['ì·¨ë“ì›”'] = df_final['ì·¨ë“ì¼ìž'].dt.month

# ---------------------------------------------------------
# 4. ì»¬ëŸ¼ì •ì˜ì„œ ê¸°ë°˜ ê²°ê³¼ Placeholder ì„¸íŒ… ë° ì¸ì½”ë”©
# ---------------------------------------------------------
# íƒ€ê²Ÿ ì„¸íŒ… (ì‹¤ì œìˆ˜ëª…: í•™ìŠµì— ì“°ì¼ Yê°’)
df_final['ì‹¤ì œìˆ˜ëª…'] = np.nan
df_final.loc[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 'ì‹¤ì œìˆ˜ëª…'] = df_final['ìš´ìš©ì—°ì°¨']

# ì»¬ëŸ¼ì •ì˜ì„œ í•„ìˆ˜ ì‚°ì¶œë¬¼ ë¹ˆì¹¸(Placeholder) ì²˜ë¦¬
# (ì´ ê°’ë“¤ì€ Phase 6 ì˜ˆì¸¡ ë‹¨ê³„ë‚˜ LLM í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì±„ì›Œì§)
df_final['ì„œë¹„ìŠ¤ê³„ìˆ˜'] = np.nan 
df_final['ì‹¤ì œìž”ì—¬ìˆ˜ëª…'] = np.where(df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y', 0.0, np.nan)
df_final['ì˜ˆì¸¡ìž”ì—¬ìˆ˜ëª…'] = np.nan
df_final['(ì›”ë³„)ê³ ìž¥ì˜ˆìƒìˆ˜ëŸ‰'] = 0
df_final['ì•ˆì „ìž¬ê³ '] = 0
df_final['(ì›”ë³„)í•„ìš”ìˆ˜ëŸ‰'] = 0
df_final['AIì˜ˆì¸¡ê³ ìž¥ì¼'] = pd.NaT
df_final['ì•ˆì „ë²„í¼'] = 0.0
df_final['ê¶Œìž¥ë°œì£¼ì¼'] = pd.NaT
df_final['ì˜ˆì¸¡ì‹¤í–‰ì¼ìž'] = today.strftime('%Y-%m-%d')

# ë²”ì£¼í˜• ìˆ˜ì¹˜í™” (ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìžˆë„ë¡ ë¼ë²¨ ì¸ì½”ë”©)
for col in ['G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ìº í¼ìŠ¤']:
    df_final[col] = df_final[col].fillna('Unknown').astype(str)
    df_final[f'{col}_Code'] = pd.factorize(df_final[col], sort=True)[0]

# ---------------------------------------------------------
# 5. ë°ì´í„° ë¶„í•  ë° ì €ìž¥ (Train / Valid / Test / Pred)
# ---------------------------------------------------------
df_train_source = df_final[df_final['í•™ìŠµë°ì´í„°ì—¬ë¶€'] == 'Y'].copy().sort_values(by='ì·¨ë“ì¼ìž')

# ì‹œê³„ì—´ì„±ì´ ìžˆëŠ” ìžì‚° ë°ì´í„°ì´ë¯€ë¡œ ëžœë¤ ì…”í”Œë§ë³´ë‹¤ëŠ” ì·¨ë“ì¼ìž ìˆœìœ¼ë¡œ ìž˜ë¼ì„œ 
# ê³¼ê±° ë°ì´í„°ë¡œ ë¯¸ëž˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” Time-Series Split ë°©ì‹ì„ í‰ë‚´ë‚´ëŠ” ê²ƒì´ ì¢‹ìŒ
n_total = len(df_train_source)
n_train, n_valid = int(n_total * 0.7), int(n_total * 0.2)

df_final['ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Prediction' # ê¸°ë³¸ê°’ì€ ì˜ˆì¸¡ ëŒ€ìƒ
df_final.loc[df_train_source.iloc[:n_train].index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Train'
df_final.loc[df_train_source.iloc[n_train : n_train + n_valid].index, 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Valid'
df_final.loc[df_train_source.iloc[n_train + n_valid:].index,  'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„'] = 'Test'

# ìµœì¢… ì¶œë ¥ ì»¬ëŸ¼ ì§€ì • (ì»¬ëŸ¼ì •ì˜ì„œ ë§¤í•‘ ë°˜ì˜ & ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
output_cols = [
    # ì •ì  & ê¸°ë³¸ ì •ë³´
    'ë¬¼í’ˆê³ ìœ ë²ˆí˜¸', 'G2Bëª©ë¡ëª…', 'ë¬¼í’ˆë¶„ë¥˜ëª…', 'ìš´ìš©ë¶€ì„œì½”ë“œ', 'ìš´ìš©ë¶€ì„œëª…', 'ìº í¼ìŠ¤',
    'ì·¨ë“ì¼ìž', 'ë°˜ë‚©ì¼ìž', 'ë¶ˆìš©ì¼ìž', 'ì²˜ë¶„ë°©ì‹', 'ë¬¼í’ˆìƒíƒœ', 'ë¶ˆìš©ì‚¬ìœ ', 'ë°˜ë‚©ì‚¬ìœ ', 
    
    # íŒŒìƒ ë³€ìˆ˜ (Features)
    'ë‚´ìš©ì—°ìˆ˜', 'ì·¨ë“ê¸ˆì•¡', 'ìš´ìš©ì—°ì°¨', 'ìž”ì—¬ë‚´ìš©ì—°ìˆ˜', 'ë¶€ì„œê°€í˜¹ë„', 'ëˆ„ì ì‚¬ìš©ë¶€í•˜',
    'ê³ ìž¥ìž„ë°•ë„', 'ê°€ê²©ë¯¼ê°ë„', 'ìž¥ë¹„ì¤‘ìš”ë„', 'ë¦¬ë“œíƒ€ìž„ë“±ê¸‰', 'ì·¨ë“ì›”',
    'G2Bëª©ë¡ëª…_Code', 'ë¬¼í’ˆë¶„ë¥˜ëª…_Code', 'ìš´ìš©ë¶€ì„œì½”ë“œ_Code', 'ìº í¼ìŠ¤_Code',
    
    # íƒ€ê²Ÿ ë° êµ¬ë¶„
    'ì‹¤ì œìˆ˜ëª…', 'í•™ìŠµë°ì´í„°ì—¬ë¶€', 'ë°ì´í„°ì„¸íŠ¸êµ¬ë¶„',
    
    # ì˜ˆì¸¡ê°’/ê²°ê³¼ê°’ (ì»¬ëŸ¼ì •ì˜ì„œ ë§¤í•‘ ì™„ë²½ ëŒ€ì‘)
    'ì„œë¹„ìŠ¤ê³„ìˆ˜', 'ì‹¤ì œìž”ì—¬ìˆ˜ëª…', 'ì˜ˆì¸¡ìž”ì—¬ìˆ˜ëª…', '(ì›”ë³„)ê³ ìž¥ì˜ˆìƒìˆ˜ëŸ‰', 'ì•ˆì „ìž¬ê³ ', 
    '(ì›”ë³„)í•„ìš”ìˆ˜ëŸ‰', 'AIì˜ˆì¸¡ê³ ìž¥ì¼', 'ì•ˆì „ë²„í¼', 'ê¶Œìž¥ë°œì£¼ì¼', 'ì˜ˆì¸¡ì‹¤í–‰ì¼ìž'
]

df_export = df_final.reindex(columns=output_cols)
save_path = os.path.join(SAVE_DIR, 'phase4_training_data.csv')
df_export.to_csv(save_path, index=False, encoding='utf-8-sig')

print("-" * 50)
print(f"âœ… ì²˜ë¶„ ì™„ë£Œ(í•™ìŠµìš©) ë°ì´í„°: {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='Y'])} ê±´ (Train/Valid/Test ë¶„í•  ì™„ë£Œ)")
print(f"âœ… ìš´ìš© ì¤‘(ì˜ˆì¸¡ìš©) ë°ì´í„° : {len(df_export[df_export['í•™ìŠµë°ì´í„°ì—¬ë¶€']=='N'])} ê±´")
print(f"ðŸ’¾ ìµœì¢… íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {save_path}")
print("-" * 50)